---
title: "Zelizer (2019) Paper Replication and Extension"
author: "Miroslav Bergam"
date: "4/14/2020"
output: bookdown::pdf_document2
bibliography: bibliography.bib
link_citations: true
---

```{r setup, include=FALSE}

knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)

#### Load libraries
library(plyr)
library(stringr)
library(ggplot2)
library(boot)
library(tidyr)
library(grid)
library(RColorBrewer)
library(bookdown)
library(reshape2)
library(grid)
library(gridExtra)
library(data.table)
library(blockTools)
library(dplyr)
library(Hmisc)
library(gt)
library(rstanarm)
library(gtable)
library(grid)

```

```{r Import Data}

load("Original-Data-and-Code/zelizer_replication_data_IPC.RData")

df$t <- relevel(as.factor(df$t) , ref = 2) ### Relevel factors so control is base category; Direct treatment: -1 is advocate; 0 is control; 1 is staffer
df$t.spill <- relevel(as.factor(df$t.spill) , ref = 2) ### Indirect treatment:  -1 is advocate; 0 is control; 1 is staffer; 2 is double staffer
for(i in 1:ncol(t.for.ri)){
  t.for.ri[,i] <- relevel(as.factor(t.for.ri[,i]) , ref = 2)
  t.spill.for.ri[,i] <- relevel(as.factor(t.spill.for.ri[,i]) , ref = 2)
}
df$treatment <- interaction(df$t,df$t.spill)

```

# Abstract

Zelizer (2019) finds that the cues that legislators take from their peers, in
addition to other credible sources of information like briefings, influence
their policymaking decisions. I succesfully replicated Zelizerâ€™s results. This
extension not only Zelizer took a Bayesian approach to his findings, running a
large number of simulations for each table using for-loops to produce estimates
and standard deviations; however, this made his code very slow and hard to run.
I used the rstanarm package to both simplify his code and to match his results
as a robustness check. Finally, I graphed the posterior predictive distributions
to analyze overall the Bayesian approach to this study. This paper serves as a
robustness test of Zelizer's results, a simplification that makes the
coefficient estimates more easily reproducable, and an analysis of the study's
Bayesian model.

# Introduction

Zelizer (2019) contributes to a body of literature identifying cue-taking from
other legislators as an influential source of information in legislator's own
policy-making experience. Early studies such as Matthews and Stimson (1975)
@side_paper_1 and Kingdon (1973) @side_paper_2 find that cue-taking has a large
influence on the decisions made by policy-makers. Zelizer uses 'inferference' --
the experimental nuisance of units interacting and affecting one another -- as
an opportunity to measure cue-taking. His first treatment variable, then, is
whether or not the legislator shares an office suite, as self-selecting to be in
an office suite and sharing a space with another legislator will inevitably lead
to the exchange of ideas. The second treatment variable is whether or not the
legislators were briefed on a particular bill. With this, the paper contributes
the literature by finding that cues complement rather than substitute other
sources of expertise, such as briefings.

I successfully replicated his results. We both used R, although I more heavily
utilized the tidyverse, gt, and rstanarm packages @r-language. I retrieved his code and data
from its posting on the Harvard Dataverse @dataverse. Although I could successfully
replicate every result using his data, the models I used in this paper fail to
recreate his standard error values due to a fundamental difference in our
models.

I simplified his code using functions from the rstanarm() package to greatly
lower the amount of time and computing power needed to run his analyses. The
methods I used maintained the Bayesian framework of the study. My producing the
same coefficients also served as a robustness test for Zelizer's findings.
Additionally, I graphed the posterior predictions for each model, visualizing
how our respective Bayesian approaches are fitting albeit imperfect given the
dataset.

# Literature Review

Studies as early as Matthews and Stimson (1975) and Kingdon (1973) find that
cue-taking has a large influence on the decisions made by policy-makers. Kingdon
concluded that cue-taking influences around 40% of decisions while Matthews and
Stimson pinned the number around 75%. More recent observational studies like
Masket (2008) found the percentage of votes influenced by cue-taking to be 10%.
Masket found that information was shared primarily through deskmates, while
Matthews and Stimson found that it was shared between friends. Coppock (2014)
found that information was shared between ideologically-similar legislators.

This paper abets the conclusion that cue-taking influences policy decisions
while updating the approach and contributing a new layer of findings. It uses a
large dataset from two legislative field experiments, lending it power that
previous studies may have lacked, and focuses on legislators who share office
suites as a measure of their influence on one another. The paper contributes the
findings that that cues complement rather than substitute other sources of
expertise as well as that cue-making's influence occurs late in the
decision-making process.

# Replication

I was able to match all of the coefficient estimates from the original paper in
my replicated figures. Zelizer gathers his Bayesian estimates using for-loops
with thousands of iterations. His original code took a large amount of time to
replicate on my own computer, so I used tools like stan_lm() from the rstanarm()
package to maintain the Bayesian integrity of the study while greatly minimizing
the computational power needed.

However, a clear downside to my approach are my inaccurate standard errors. I
was able to replicate every standard error when using Zelizer's code, but my
method didn't account for certian intricacies in the data. In one of the two
studies captured in the data, legislators were not eligable for briefings from
the staffer/advocate. This leads to implicit clustering in the data of those who
were not briefed (one of the treatment variables). As a result, the standard
errors produced by my Bayesian stan_lm models are too small because it assumes
that all participants in the study receieved a briefing and that therefore is a
large population of legislators (from that study) who by default have no
variability in this briefing treatment.

Therefore, while I am able to replicate the standard errors using the original
replication code, the method used in this paper produces overly narrow standard
errors that don't take into consideration implicit clustering. Zelizer's more
accurate method works arounnd this issue using a particular form of
Randomization Inference.

# Extension

See the figure "Posterior Predictive Distributions For All Models" in Appendix.
In each of the plots, the darker line shows the distribution of the
observed data regarding their treatments, cosponsorships, and other variables.
The more faded lines show the how the model I passed in for each respective plot
fits their associated data. The resulting finding apply across all of the models
used in the study: a Bayesian approach is an effective but imperfect way of
fitting this data to a model. The grey lines shows the Bayesian model use this
discrete data in non-discrete ways, as seen by the continuous distributions.
Additionally, it extrapolates the data, producing results that are below zero
despite the data not dipping below 0. However, the peaks of the two lines both
consistently center around the same value (around 0), showing that it is
somewhat accruate. As a result, I've determined that the Bayesian model both
Zelizer and I use to produce our coefficient results is a flawed but accruate
way of fitting the data.

# Conclusion

Zelizer (2019) identifies cue-taking from other legislators as an influential
source of information in a legislator's policy-making decision. Making briefings
a treatment variable in addition to contact with other legislators, Zelizer
contributes to the literature that cue-taking is a complement rather than
substitute for other modes of information.

I was successful in replication Zelizer's results, although when using my code
as opposed to his, my standard errors fail to match his as they do not use
Randomization Inference. In addition to simplifying his code while maintaining
its Bayesian framework, producing the same coefficients served as a robustness
test for Zelizer's findings. I also graphed the posterior predictions for each
model to visualize how our Bayesian approach is a flawed but effective approach
to this dataset.

Both approaches to the study come with pros and cons: Zelizer's original code
allows for a more nuanced calculation of the standard error by using thousands
of iterations to perform Randomization Inference. However, these iterations make
the code slow and cumbersome for those looking to replicate the experiment. A
future extension would involve performing Randomization Inference using the
quicker, more efficient methods used by the rstanarm package.


^[[All analysis for this paper is availible at https://github.com/mirobergam/Replication-paper](https://github.com/mirobergam/Replication-paper)]

# Figures 

## Table 3

```{r Table 3}

### Table 3:
table3 <- subset(df , office.size > 1) %>%
  ddply(. , .(treatment) , function(x) out = data.frame(
    Weighted.Mean = round(weighted.mean(x$cosp , x$ipw),3) ,
    N = length(x$cosp))) %>%
  mutate(treatment = as.integer(treatment)) %>%
  filter(treatment == 1 | treatment == 3 | treatment == 7 | treatment == 9)

treatments3 <- tibble(treatment = c(1,3,7,9),
                      `Cue-Taking` = c("NO CUE-TAKING", "NO CUE-TAKING", 
                                       "YES CUE-TAKING", "YES CUE-TAKING"),
                      Briefing = c("NO", "YES", "NO", "YES"))

table3 <- treatments3 %>% left_join(table3, by = "treatment") %>%
  mutate(Weighted.Mean = Weighted.Mean * 100) %>%
  mutate(Weighted.Mean = as.character(Weighted.Mean)) %>%
  mutate(N = as.character(N)) %>%
  mutate(`Mean(N)` = paste(Weighted.Mean," (", N, ")")) %>%
  select(`Cue-Taking`, Briefing, `Mean(N)`)  %>%
  pivot_wider(names_from = `Cue-Taking`, values_from = `Mean(N)`)

gt(table3) %>% 
  tab_header(
    title = "Table 3",
    subtitle = "Summary of Cosponsorship by Briefing and Cue-Taking Assignment (in pp)"
  )

```

## Table 4

```{r}

## pp_check(model, "dens_overlay") # takes the original data and show in a really dark apttern, and show the bayesian runs of it in the background to see how well the data ftis
# weird fit
# because these are discrete values the model ended up matching up weird but its decent. bayesian model assu,es conntinues. <ike for example the tail extends past 0. try to make it discrete instead of continiuous

x <- stan_lm(cosp ~ treatment + bill + leg, data = subset(df , office.size > 1), weights=ipw, refresh = FALSE, prior = NULL)

#summary(x, digits = 10)

x_coef <- x$coefficients[c('treatment1.0','treatment0.1','treatment1.1')]
x_ses <- x$ses[c('treatment1.0','treatment0.1','treatment1.1')]

x_final <- rbind(x_coef, x_ses)
x_final <- as_tibble(x_final)

x_final <- x_final %>%
  mutate(Combined = round(`treatment1.1` * 100, 2),
         Briefing = round(`treatment1.0` * 100, 2),
         `Cue-Taking` = round(`treatment0.1` * 100, 2),
         Value = c("ITT", "SE")) %>%
  select(Value, Briefing, `Cue-Taking`, Combined)

gt(x_final) %>% 
  tab_header(
    title = "Table 4",
    subtitle = "Estimated Briefing and Cue-Taking Effects (in pp)"
  )

```

## Table 5

```{r Table 5}

y1 <- stan_lm(cosp ~ treatment + bill + leg, data = subset(df , office.size > 1 & passed==0), weights=ipw, refresh = FALSE, prior = NULL)

y2 <- stan_lm(cosp ~ treatment + bill + leg, data = subset(df , office.size > 1 & passed==1), weights=ipw, refresh = FALSE, prior = NULL)

#summary(x, digits = 10)

y1_coef <- y1$coefficients[c('treatment1.0','treatment0.1','treatment1.1')]
y1_ses <- y1$ses[c('treatment1.0','treatment0.1','treatment1.1')]
y2_coef <- y2$coefficients[c('treatment1.0','treatment0.1','treatment1.1')]
y2_ses <- y2$ses[c('treatment1.0','treatment0.1','treatment1.1')]

y_final <- rbind(y1_coef, y1_ses, y2_coef, y2_ses)
y_final <- as_tibble(y_final)

y_final <- y_final %>%
  mutate(Combined = round(`treatment1.1` * 100, 2),
         Briefing = round(`treatment1.0` * 100, 2),
         `Cue-Taking` = round(`treatment0.1` * 100, 2),
         Value = c("ITT", "SE", "ITT", "SE"),
         `Reached Floor?` = c("Bills that failed in committee",
                              "",
                              "Bills that reached floor",
                              "")) %>%
  select(`Reached Floor?`, Value, Briefing, `Cue-Taking`, Combined)

gt(y_final) %>% 
  tab_header(
    title = "Table 5",
    subtitle = "Estimated Briefing and Cue-Taking Effects by Bill Progress (in pp)"
  )


```

## Table 6

```{r}

set.seed(1006)

z1 <- stan_lm(cosp ~ treatment + bill + leg, 
   data = subset(df , office.size > 1 & 
                   !is.na(t.spill.desk) &
                   !is.na(t.spill.dist) &
                   !is.na(t.spill.ideo)),
   weights=ipw, refresh = FALSE, prior = NULL)

z2 <- stan_lm(cosp ~ treatment.desk + bill + leg,
   data = subset(df , office.size > 1 &
                   !is.na(t.spill.desk) &
                   !is.na(t.spill.dist) &
                   !is.na(t.spill.ideo)),
   weights=ipw.desk, refresh = FALSE, prior = NULL)

z3 <- stan_lm(cosp ~ treatment.dist + bill + leg,
   data = subset(df , office.size > 1 &
                   !is.na(t.spill.desk) &
                   !is.na(t.spill.dist) &
                   !is.na(t.spill.ideo)),
   weights=ipw.desk, refresh = FALSE, prior = NULL)

z4 <- stan_lm(cosp ~ treatment.ideo + bill + leg,
         data = subset(df , office.size > 1 &
                         !is.na(t.spill.desk) &
                         !is.na(t.spill.dist) &
                         !is.na(t.spill.ideo)),
         weights=ipw.ideo, refresh = FALSE, prior = NULL)

z1_coef <- z1$coefficients[c('treatment1.0','treatment0.1','treatment1.1')] %>% as_tibble() %>% mutate(value = value * 100) %>% round(2)

z1_ses <- z1$ses[c('treatment1.0','treatment0.1','treatment1.1')] %>% as_tibble() %>% mutate(value = value * 100) %>% round(2)

z2_coef <- z2$coefficients[c('treatment.desk1.0','treatment.desk0.1','treatment.desk1.1')] %>% as_tibble() %>% mutate(value = value * 100) %>% round(2)

z2_ses <- z2$ses[c('treatment.desk1.0','treatment.desk0.1','treatment.desk1.1')]%>% as_tibble() %>% mutate(value = value * 100) %>% round(2)

z3_coef <- z3$coefficients[c('treatment.dist1.0','treatment.dist0.1','treatment.dist1.1')] %>% as_tibble() %>% mutate(value = value * 100) %>% round(2)

z3_ses <- z3$ses[c('treatment.dist1.0','treatment.dist0.1','treatment.dist1.1')] %>% as_tibble() %>% mutate(value = value * 100) %>% round(2)

z4_coef <- z4$coefficients[c('treatment.ideo1.0','treatment.ideo0.1','treatment.ideo1.1')] %>% as_tibble() %>% mutate(value = value * 100) %>% round(2)

z4_ses <- z4$ses[c('treatment.ideo1.0','treatment.ideo0.1','treatment.ideo1.1')] %>% as_tibble() %>% mutate(value = value * 100) %>% round(2)

z_final <- z1_coef %>%
  mutate(`Model (SE)` = c("Briefing", "Cue-Taking", "Combined"),
        `Offices` = as.character(z1_coef$value),
        `Office SE`= as.character(z1_ses$value),
        `Office (SE)` = paste(`Offices`," (", `Office SE`, ")"),
        `Desks`= as.character(z2_coef$value),
        `Desks SE`= as.character(z2_ses$value),
        `Desks (SE)` = paste(`Desks`," (", `Desks SE`, ")"),
        `Districts`= z3_coef$value,
        `Districts SE`= z3_ses$value,
        `Districts (SE)` = paste(`Districts`," (", `Districts SE`, ")"),
        `Ideology`= z4_coef$value,
        `Ideology SE`= z4_ses$value,
        `Ideology (SE)` = paste(`Ideology`," (", `Ideology SE`, ")")) %>%
  select(`Model (SE)`, `Office (SE)`, `Desks (SE)`, `Districts (SE)`, `Ideology (SE)`)

gt(z_final) %>%
  tab_header(
    title = "Table 6",
    subtitle = "Estimated Briefing and Cue-Taking Effects Under Alternate Spillover Models (in pp)"
  )

```

## Figure 3

```{r}

load("Original-Data-and-Code/zelizer_replication_data_dates_IPC.RData")

nsims <- 50

df$treatment <- interaction(df$t,df$t.spill)
nDays <- seq(0,98,7)
days.ri <- data.frame(matrix(NA,nrow=length(nDays) , ncol = 3))
days.ri.SE <- data.frame(matrix(NA,nrow=length(nDays) , ncol = 3))

for(i in nDays){
  Ydays <- as.numeric(!is.na(df$days) & df$days <= i & df$days >=0 & df$cosp==1)
  days.ri[match(i,nDays),1:3] <- summary(lm(Ydays ~ treatment + bill + leg ,
                                            data = df,
                                            weights=ipw))$coef[c('treatment1.0','treatment0.1','treatment1.1'),'Estimate']
  temp <- data.frame(matrix(NA,nrow=nsims,ncol=3))
  for(j in 1:nsims){
    treatment.sim <- interaction(t.for.ri2[,j],t.spill.for.ri2[,j])
    levels(treatment.sim)
    temp[j,1:3] <- summary(lm(Ydays ~ treatment.sim + bill + leg ,
                              data = df,
                              weights=ipw.for.ri2[,j]))$coef[c('treatment.sim1.0','treatment.sim0.1','treatment.sim1.1'),'Estimate']
  }
  temp <- apply(temp , 2 , sd)
  days.ri.SE[match(i,nDays),1:3] <- temp
}

tempnum <- 1
data.frame(ATE = days.ri[,tempnum],
           CIlow = days.ri[,tempnum] - 1.65*days.ri.SE[,tempnum],
           CIhigh = days.ri[,tempnum] + 1.65*days.ri.SE[,tempnum],
           X = nDays/7) %>%
  ggplot(., aes(x = factor(X) )) +
  geom_errorbar(aes(ymin = CIlow*100 , ymax = CIhigh*100 , width = 0)) +
  geom_point(aes(y = ATE*100)) +
  scale_y_continuous(minor_breaks=waiver(), labels = waiver(), breaks=c(-2,0,2,4,6,8) , limits = c(-2,9)) +
  labs(title = "Figure 3. Briefing Effects by Date of Cosponsorship",
       x = "Week of Session", 
       y = "Est. ATE (perc. pts.)") +
  geom_smooth(aes(y = ATE*100) , col = "black" , method = "loess" , se = FALSE) +
  geom_vline(xintercept=0 , color = "#535353" , lwd = 1) +
  geom_hline(yintercept=0 , color = "#535353" , lwd = 1) +
  theme(panel.background = element_blank(),
        panel.grid = element_blank(),
        axis.ticks = element_blank(),
        title = element_text(color = "#535353" , size = 14, face="bold"),
        axis.title.x = element_text(color = "#535353" , size = 12, face="bold"),
        axis.title.y = element_text(color = "#535353" , size = 12, face="bold"),
        axis.text.y = element_text(size = 12, colour = "grey50"),
        axis.text.x = element_text(size = 8, colour = "grey50"),
        panel.border = element_blank(),
        legend.key = element_rect(colour = "white",fill = "white"),
        legend.text = element_text(size=10,color="grey50"),
        legend.title = element_text(size = 11, face = "bold", colour = "#535353"),
        strip.text.x = element_text(size = 11, face = "bold", colour = "#535353"),
        strip.background = element_rect(colour = "white", fill = "white"),
        legend.position="right",
        plot.margin = unit(c(0.75,0.75,0.75,0.75), "cm"))


```

## Figure 4

```{r}

tempnum <- 2
data.frame(ATE = days.ri[,tempnum],
           CIlow = days.ri[,tempnum] - 1.65*days.ri.SE[,tempnum],
           CIhigh = days.ri[,tempnum] + 1.65*days.ri.SE[,tempnum],
           X = nDays/7) %>%
  ggplot(., aes(x = factor(X) )) +
  geom_errorbar(aes(ymin = CIlow*100 , ymax = CIhigh*100 , width = 0)) +
  geom_point(aes(y = ATE*100)) +
  scale_y_continuous(minor_breaks=waiver(), labels = waiver(), breaks=c(-2,0,2,4,6,8) , limits = c(-2,9)) +
  labs(title = "Figure 4. Cue-Taking Effects by Date of Cosponsorship",
       x = "Week of Session",
       y = "Est. ATE (perc. pts.)") +
  geom_smooth(aes(y = ATE*100) , col = "black" , method = "loess" , se = FALSE) +
  geom_vline(xintercept=0 , color = "#535353" , lwd = 1) +
  geom_hline(yintercept=0 , color = "#535353" , lwd = 1) +
  theme(panel.background = element_blank(),
        panel.grid = element_blank(),
        axis.ticks = element_blank(),
        title = element_text(color = "#535353" , size = 14, face="bold"),
        axis.title.x = element_text(color = "#535353" , size = 12, face="bold"),
        axis.title.y = element_text(color = "#535353" , size = 12, face="bold"),
        axis.text.y = element_text(size = 12, colour = "grey50"),
        axis.text.x = element_text(size = 8, colour = "grey50"),
        panel.border = element_blank(),
        legend.key = element_rect(colour = "white",fill = "white"),
        legend.text = element_text(size=10,color="grey50"),
        legend.title = element_text(size = 11, face = "bold", colour = "#535353"),
        strip.text.x = element_text(size = 11, face = "bold", colour = "#535353"),
        strip.background = element_rect(colour = "white", fill = "white"),
        legend.position="right",
        plot.margin = unit(c(0.75,0.75,0.75,0.75), "cm"))

```

## Posterior Predictive Distributions

```{r PPDs}

ppd4 <- pp_check(x, "dens_overlay")

ppd51 <- pp_check(y1, "dens_overlay")

ppd52 <- pp_check(y2, "dens_overlay")

ppd61 <- pp_check(z1, "dens_overlay")

ppd62 <- pp_check(z2, "dens_overlay")

ppd63 <- pp_check(z3, "dens_overlay")

ppd64 <- pp_check(z4, "dens_overlay")

grid.arrange(ppd4, ppd51, ppd52, ppd61,
             ppd62, ppd63, ppd64,
             ncol = 2,
             nrow = 4,
             top = textGrob("Posterior Predictive Distributions For All Models",
                            gp = gpar(fontsize = 18)),
             bottom = textGrob("Models from left to right: Table 4, Table 5 (bill didn't pass), Table 5 (bill passed),
                               Table 6 (Offices), Table 6 (Desks), Table 6 (Districts), Table 6 (Ideology)",
                            gp = gpar(fontsize = 9)))

```

## Bibliography

@main_paper @side_paper_1 @side_paper_2 @dataverse @r-language
